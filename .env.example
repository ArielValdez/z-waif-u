#Enter your whisper model, see VRAM requirement for further details at whisper Github | tiny, base, small, tiny.en, base.en
WHISPER_MODEL = base

#Use the (roughly 4x faster) whisper-turbo library. Requires CUDA Toolkit and cuDNN downloaded to work with GPU.
FASTER_WHISPER = OFF
FASTER_WHISPER_CPU_TRANSCRIPTION = OFF

#Make the speech to text split into chunks and calculate as you speak? (Lower = less percise, but calculates more often. 300 - 1200 is resonable)
WHISPER_CHUNKY = ON
WHISPER_CHUNKY_RATE = 710
WHISPER_CHUNKS_MAX = 14

#Name that you want your bot/waifu to have (used in like 2 places, unimportant)
CHAR_NAME = Waifu

#Use the name of the Ooobabooga character card you want.
CHARACTER_CARD = Waifu

#Enter your name that you entered while creating Character card. Typically User, You or if have entered your name.
YOUR_NAME = You

#Decide if hotkeys should be on or off when the program/waifu first boots. Valid values are "ON" and "OFF"
HOTKEYS_BOOT = OFF

#Decide if "Newline Cut" and "RP Supression" should start "ON" or "OFF".
NEWLINE_CUT_BOOT = OFF
RP_SUP_BOOT = ON

#API type (either Oobabooga or Ollama. For other Openai-styled endpoints, do Oobabooga)
API_TYPE = Oobabooga

#Ollama Options. A visual model only runs when using multimodal / when sending images. If pointed at the same model, it can be used for both (saves VRAM).
#Visual model only loaded if MODULE_VISUAL is "ON".
ZW_OLLAMA_MODEL = "nsheth/llama-3-lumimaid-8b-v0.1-iq-imatrix"
ZW_OLLAMA_MODEL_VISUAL = "nsheth/llama-3-lumimaid-8b-v0.1-iq-imatrix"

#Use the streaming API for Oobabooga/Ollama? Disable this if you are having issues getting responses.
API_STREAM_CHATS = ON

#Maximum context length to tell the model to look at. More takes more VRAM and longer to generate, generally.
#TOKEN_LIMIT is for the actual ML portion and the actual cutoff, MESSAGE_PAIR_LIMIT just decides how much to send to it.
TOKEN_LIMIT = 4096
MESSAGE_PAIR_LIMIT = 30

#Share the current time with the bot?
TIME_IN_ENCODING = ON

#Info for the model link
#Works with any OpenAI-compatible LLM server, such as oobabooga/text-generation-webui, ollama in server mode, or other OpenAI endpoints.
HOST_PORT = 127.0.0.1:5000

# Visual model info
IMG_PORT = 127.0.0.1:5007
OOBA_VISUAL_CHARACTER_NAME = Z-WAIF-VisualAssist
OOBA_VISUAL_PRESET_NAME = Z-WAIF-VisualPreset
OLLAMA_VISUAL_ENCODE_GUIDANCE = ON
# Valid values for the character card are: "VISUAL", "BASE", "OFF"
OLLAMA_VISUAL_CARD = VISUAL

#How should we scale the image? 1.0 = Small (for Oobabooga), 1.6 = Big (for Ollama). Sane values are 0.4 - 4.0.
IMG_SCALE = 1.0

#What you want your VTuber's eyes to move to. Default gives control to the model. Values can be: "Faces", "Random", "None". Requires setting up in the model.
EYES_FOLLOW = "None"
EYES_START_ID = 14

#Mininum recording time for an autochat to actually register
AUTOCHAT_MIN_LENGTH = 157

#Should we use Silero VAD for our Autochat, or just the normal volume based one? Options = "ON", "OFF"
SILERO_VAD = ON

#Decides of each of these modules should be running. Recommended to turn on RAG after a few hours of use, for better memory. Valid "ON" or "OFF".
MODULE_MINECRAFT = OFF
MODULE_GAMING = OFF
MODULE_ALARM = OFF
MODULE_VTUBE = OFF
MODULE_DISCORD = OFF
MODULE_RAG = OFF
MODULE_VISUAL = OFF
MODULE_TWITCH = OFF

# Twitch Bot Configuration - Get these from https://dev.twitch.tv/console/apps
# Create a new application, set OAuth Redirect URL to: http://localhost:17563
# TWITCH_TOKEN should be an OAuth token (without oauth: prefix, it will be added automatically)
TWITCH_TOKEN = your_twitch_oauth_token_here
TWITCH_CLIENT_ID = your_twitch_client_id_here
TWITCH_CHANNEL = your_twitch_channel_name_here


TWITCH_PERSONALITY = friendly
TWITCH_AUTO_RESPOND = ON
TWITCH_RESPONSE_CHANCE = 0.8
TWITCH_COOLDOWN_SECONDS = 3
TWITCH_MAX_MESSAGE_LENGTH = 450


# Instructions for getting Twitch credentials:
# 1. Go to https://dev.twitch.tv/console/apps
# 2. Click "Create App" 
# 3. Give it a name like "Z-WAIF Bot"
# 4. Set OAuth Redirect URL to: http://localhost:17563
# 5. Set Category to "Chat Bot"
# 6. Copy the Client ID
# 7. Generate a new Client Secret (this becomes your TWITCH_TOKEN)
# 8. Set TWITCH_CHANNEL to your Twitch username (lowercase)

# Settings explanation:
# MODULE_TWITCH = ON/OFF - Enable/disable the entire Twitch module
# TWITCH_PERSONALITY = friendly/enthusiastic/sarcastic/supportive/casual/playful - AI personality
# TWITCH_AUTO_RESPOND = ON/OFF - Whether to automatically respond to chat messages
# TWITCH_RESPONSE_CHANCE = 0.0-1.0 - Probability of responding to each message (0.8 = 80%)
# TWITCH_COOLDOWN_SECONDS = Number of seconds between AI responses
# TWITCH_MAX_MESSAGE_LENGTH = Maximum length for AI responses 
